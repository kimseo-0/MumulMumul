# interactive_chatbot.py
"""
ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ì„œ í…ŒìŠ¤íŠ¸í•˜ê¸°
"""
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv

load_dotenv()

def ask(q: str, db_path: str) -> str:
    vs = Chroma(
        persist_directory=db_path, 
        embedding_function=OpenAIEmbeddings(model="text-embedding-3-small"), 
        collection_name="control_statement"
    )
    llm = ChatOpenAI(model="gpt-4o-mini")
    is_learning = "YES" in llm.invoke(f"í•™ìŠµì§ˆë¬¸ì´ë©´YES ì•„ë‹ˆë©´NO: {q}").content
    
    if is_learning:
        docs = vs.similarity_search(q, k=3)
        context = "\n".join([d.page_content for d in docs])
        return llm.invoke(f"ìë£Œ:\n{context}\n\nì§ˆë¬¸: {q}\n\në‹µë³€í•˜ì„¸ìš”.").content
    else:
        return llm.invoke(f"{q}\nê°„ë‹¨ë‹µë³€+í•™ìŠµì§ˆë¬¸ìœ ë„").content


# ===== ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ =====
if __name__ == "__main__":
    DB_PATH = "C:/POTENUP/MumulMumul/storage/vectorstore"
    
    print("="*60)
    print("ğŸ¤– ë¨¸ë¬¼ë¨¸ìš¸ í•™ìŠµ ë„ìš°ë¯¸ (ëŒ€í™”í˜• ëª¨ë“œ)")
    print("="*60)
    print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    print("="*60)
    
    while True:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        question = input("\nğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        # ì¢…ë£Œ ëª…ë ¹ì–´ ì²´í¬
        if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!")
            break
        
        # ë¹ˆ ì…ë ¥ ë¬´ì‹œ
        if not question:
            print("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            continue
        
        # ë‹µë³€ ìƒì„±
        print("\nâ³ ë‹µë³€ ìƒì„± ì¤‘...")
        try:
            answer = ask(question, DB_PATH)
            print(f"\nğŸ¤– ë‹µë³€:\n{answer}")
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("\n" + "-"*60)
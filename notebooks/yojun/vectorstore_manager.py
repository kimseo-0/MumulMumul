import os
import re
from dotenv import load_dotenv
from openai import OpenAI
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

import pytesseract
from PIL import Image
import fitz  # PyMuPDF
from langchain_core.documents import Document

load_dotenv()
client = OpenAI()


def ocr_pdf(pdf_path):
    """í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” í˜ì´ì§€ë¥¼ OCRë¡œ ì½ì–´ì„œ Document ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    ocr_docs = []
    pdf = fitz.open(pdf_path)

    for page_idx in range(len(pdf)):
        page = pdf[page_idx]

        # ì´ë¯¸ì§€ ë Œë”ë§
        pix = page.get_pixmap()
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = pytesseract.image_to_string(img, lang="kor+eng")

        ocr_docs.append(
            Document(
                page_content=text,
                metadata={"page": page_idx + 1}
            )
        )

    return ocr_docs


def translate_title_to_english(title: str) -> str:
    """í•œê¸€ PDF ì œëª©ì„ ì˜ì–´ í´ë”ëª…ìœ¼ë¡œ ë³€í™˜"""
    prompt = f"""
    Convert this Korean lecture PDF title into a natural English folder name.
    Conditions:
    - Use underscores instead of spaces
    - Remove special characters
    - Keep the meaning clear
    Title: {title}
    """

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return resp.choices[0].message.content.strip().lower()


def sanitize(name: str) -> str:
    """í´ë”ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    name = name.lower()
    name = re.sub(r"[^a-z0-9_-]+", "_", name)
    name = re.sub(r"_+", "_", name)
    name = name.strip("_-")
    if len(name) < 3:
        name = "db_" + name
    return name


def save_month_folder_to_vectorstore(month_folder: str, db_root: str, month: str):
    """ì›”ë³„ í´ë”ì˜ PDFë¥¼ í•˜ë‚˜ì”© ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ (PDFë³„ ê°œë³„ Chromaë¡œ ì €ì¥)"""

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    embedding = OpenAIEmbeddings(model="text-embedding-3-large")

    # lecture_08 ê°™ì€ ì›”ë³„ í´ë” ìƒì„±
    month_path = os.path.join(db_root, f"lecture_{month}")
    os.makedirs(month_path, exist_ok=True)

    # PDF í•˜ë‚˜ì”© ì²˜ë¦¬
    for filename in os.listdir(month_folder):
        if not filename.endswith(".pdf"):
            continue

        original_title = os.path.splitext(filename)[0]

        print(f"\nğŸ“˜ ì œëª© ë²ˆì—­ ì¤‘ â†’ {original_title}")
        eng_title = translate_title_to_english(original_title)
        safe_name = sanitize(eng_title)
        print(f"â¡ ì˜ì–´ í´ë”ëª… ìƒì„±: {safe_name}")

        pdf_path = os.path.join(month_folder, filename)

        # PyMuPDFLoaderë¡œ ë¡œë”© ì‹œë„
        loader = PyMuPDFLoader(pdf_path)
        docs = loader.load()

        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ OCR fallback
        if len(docs) == 0 or all(len(d.page_content.strip()) == 0 for d in docs):
            print("âš  PyMuPDFLoader í…ìŠ¤íŠ¸ ì—†ìŒ â†’ OCR ì‹¤í–‰")
            docs = ocr_pdf(pdf_path)

        total_pages = len(docs)

        # chunk ìƒì„±
        chunk_docs = []
        for doc_idx, doc in enumerate(docs):
            chunk_texts = splitter.split_text(doc.page_content)

            for chunk in chunk_texts:
                chunk_docs.append(
                    Document(
                        page_content=chunk,
                        metadata={
                            "month": month,
                            "filename": original_title,
                            "filename_eng": safe_name,
                            "page": doc_idx + 1,
                            "total_pages": total_pages
                        }
                    )
                )

        # PDF ì´ë¦„ìœ¼ë¡œ ê°œë³„ ì €ì¥ ê²½ë¡œ ìƒì„±
        store_path = os.path.join(month_path, safe_name)
        os.makedirs(store_path, exist_ok=True)

        # PDFë³„ ë…ë¦½ Chroma ì €ì¥
        Chroma.from_documents(
            documents=chunk_docs,
            embedding=embedding,
            persist_directory=store_path,
            collection_name=safe_name
        )

        print(f"âœ” ì €ì¥ ì™„ë£Œ â†’ {store_path}")

    print("\nğŸ‰ ì „ì²´ ë²¡í„° ì €ì¥ ì™„ë£Œ!")

# chatbot_rag_optimized.py

import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import pandas as pd
from operator import itemgetter

load_dotenv()

# ==============================================================
# ê¸°ë³¸ ì„¤ì •
# ==============================================================

DB_PATH = r"C:\POTENUP\MumulMumul\storage\vectorstore\curriculum_all_new"
COLLECTION = "curriculum_all_new"

LLM_MODEL = "gpt-4o-mini"
EMBEDDING_MODEL = "text-embedding-3-large"

SEARCH_K = 5
FETCH_K = 20

# ==============================================================
# ìˆ˜ì¤€ë³„ ë‹µë³€ ê·œì¹™
# ==============================================================

GRADE_RULES = {
    "ì´ˆê¸‰": """
ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë°/ë°ì´í„° ë¶„ì•¼ë¥¼ ì²˜ìŒ ë°°ìš°ëŠ” ì´ˆê¸‰ìë¥¼ ë•ëŠ” í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì„¤ëª…ì€ ë°˜ë“œì‹œ ì‰¬ìš´ í•œêµ­ì–´ë¡œ, ì§§ì€ ë¬¸ì¥ ìœ„ì£¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ 6ë‹¨ê³„ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.

-------------------------------------

1) [ì§ˆë¬¸ ì´í•´]
- ì‚¬ìš©ìê°€ ì•Œê³  ì‹¶ì–´í•˜ëŠ” ë‚´ìš©ì„ í•œ ì¤„ë¡œ ë‹¤ì‹œ ì •ë¦¬í•©ë‹ˆë‹¤.
- ì „ë¬¸ìš©ì–´ ì—†ì´, ì‰¬ìš´ í•œêµ­ì–´ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.

2) [í•µì‹¬ í•œ ì¤„ ìš”ì•½]
- ê²°ë¡ ì„ ê°€ì¥ ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ í•œ ë¬¸ì¥ì— ìš”ì•½í•©ë‹ˆë‹¤.
- ì´ˆê¸‰ìê°€ ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

3) [ì‰¬ìš´ ì„¤ëª…]
- ì–´ë ¤ìš´ ìš©ì–´, ì˜ì–´, ì¶•ì•½ì–´ëŠ” ìµœëŒ€í•œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¶€ë“ì´í•˜ê²Œ ì „ë¬¸ìš©ì–´ê°€ ë“±ì¥í•˜ë©´:
  â†’ ì¦‰ì‹œ ê´„í˜¸ ì•ˆì— ì‰¬ìš´ ëœ»ì„ ì ìŠµë‹ˆë‹¤.
  ì˜ˆ: â€œë¼ì´ë¸ŒëŸ¬ë¦¬(ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” ê¸°ëŠ¥ ë¬¶ìŒ)â€

4) [ë¹„ìœ  / ì˜ˆì‹œ]
- í˜„ì‹¤ ë¹„ìœ  1ê°œ ì´ìƒì„ ì œê³µí•©ë‹ˆë‹¤.
- ì˜ˆì‹œ ì½”ë“œ 1ê°œë¥¼ ì œê³µí•˜ë˜, ë„ˆë¬´ ê¸¸ê²Œ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.

5) [ì¶”ê°€ë¡œ ì•Œë©´ ì¢‹ì€ ê²ƒ]
- ì´ˆê¸‰ìê°€ ë¶€ë‹´ ì—†ì´ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆì„ ì •ë„ë¡œ 1~2ì¤„ë§Œ í™•ì¥ ì„¤ëª…í•©ë‹ˆë‹¤.

6) [ì¶œì²˜]
- ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ í‘œê¸°í•©ë‹ˆë‹¤.
  íŒŒì¼ëª….pdf / p.ìˆ«ì ë˜ëŠ” p.ìˆ«ìâ€“ìˆ«ì

-------------------------------------

[íŠ¹ë³„ ì£¼ì˜ ì‚¬í•­]
- ë¬¸ì¥ì€ ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.
- ì´ˆê¸‰ìê°€ ëª¨ë¥¼ ë§Œí•œ ê°œë…ì€ ë°˜ë“œì‹œ í’€ì–´ì„œ ì„¤ëª…í•©ë‹ˆë‹¤.
- context(ê°•ì˜ìë£Œ)ì— ì—†ëŠ” ë‚´ìš©ì€ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
""",
    "ì¤‘ê¸‰": """
- ê°œë…ì˜ í•µì‹¬ ì •ì˜ë¥¼ ì •í™•í•˜ê²Œ ì œê³µ
- í•„ìš” ì‹œ ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜ ë¶ˆí•„ìš”í•œ í™•ì¥ ê¸ˆì§€
- ì™œ ì´ëŸ° ê°œë…ì´ í•„ìš”í•œì§€ 1ë²ˆ ì„¤ëª…
- ì‹¤ë¬´ì—ì„œ í—·ê°ˆë¦¬ëŠ” í¬ì¸íŠ¸ë„ í•¨ê»˜ ì œê³µ
""",
    "ê³ ê¸‰": """
- ë‚´ë¶€ ë™ì‘ ì›ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
- êµ¬ì¡°, ë©”ì»¤ë‹ˆì¦˜, ë©”ëª¨ë¦¬Â·ì„±ëŠ¥ ë“± ì‹¬í™” ë‚´ìš© í¬í•¨ ê°€ëŠ¥
- í•„ìš”í•œ ê²½ìš° ìˆ˜ì‹Â·ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥
- ë‹¤ë¥¸ ê¸°ìˆ ê³¼ ë¹„êµ ì„¤ëª… ê°€ëŠ¥
"""
}

# ==============================================================
# RAG ì²´ì¸ ì´ˆê¸°í™”
# ==============================================================

def initialize_rag_chain():
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)

    vectorstore = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings,
        collection_name=COLLECTION,
    )

    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": SEARCH_K, "fetch_k": FETCH_K}
    )

    # ----------------------------
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìµœì í™” ë²„ì „)
    # ----------------------------
    template = """
    ë‹¹ì‹ ì€ ë¶€íŠ¸ìº í”„ í•™ìƒì„ ìœ„í•œ í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ì…ë‹ˆë‹¤.
    ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ [Context] ì•ˆì˜ ì •ë³´ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

    [í•™ìƒ ìˆ˜ì¤€]
    {grade}

    [ë‹µë³€ ê·œì¹™]
    {grade_rules}

    [ë‹µë³€ ì¡°ê±´]
    - ì„¤ëª…ì€ ë°˜ë“œì‹œ í•™ìƒ ìˆ˜ì¤€ì— ë§ì¶°ì„œ ì‘ì„±
    - ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±
    - ì¶œì²˜(íŒŒì¼ëª…, í˜ì´ì§€ ë“±) ë°˜ë“œì‹œ ëª…ì‹œ
    - Context ë°”ê¹¥ ì •ë³´ëŠ” ì‚¬ìš© ê¸ˆì§€

    -------------------------
    [Context]
    {context}

    [Question]
    {question}
    -------------------------
    """

    prompt = ChatPromptTemplate.from_template(template)
    model = ChatOpenAI(model=LLM_MODEL, temperature=0.2)

    rag_chain = (
        {
            # ì§ˆë¬¸ ë¬¸ìì—´ë§Œ êº¼ë‚´ì„œ retrieverì— ì „ë‹¬
            "context": itemgetter("question") | retriever,
            # ë‚˜ë¨¸ì§€ë„ ê°ê° í•„ìš”í•œ í‚¤ë§Œ ì „ë‹¬
            "question": itemgetter("question"),
            "grade": itemgetter("grade"),
            "grade_rules": itemgetter("grade_rules"),
        }
        | prompt
        | model
        | StrOutputParser()
    )
    return rag_chain

# ==============================================================
# History ê¸°ë°˜ ë©€í‹°í„´ ì§€ì› í•¨ìˆ˜ ì¶”ê°€
# ==============================================================

def build_history_text(history, max_turns=3):
    """
    ìµœê·¼ max_turnsê°œì˜ ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ í•©ì³ ë°˜í™˜.
    GPTê°€ ì´ì „ ë§¥ë½ì„ ì´í•´í•˜ë„ë¡ ë„ì™€ì¤€ë‹¤.
    """
    if not history:
        return ""

    recent = history[-max_turns:]

    hist_text = ""
    for turn in recent:
        hist_text += f"í•™ìƒ: {turn['question']}\n"
        hist_text += f"AI: {turn['answer']}\n\n"

    return hist_text


def answer_with_history(question, grade, history):
    """
    ë©€í‹°í„´ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜:
    - ìµœê·¼ historyë¥¼ ì‹œìŠ¤í…œ promptì— ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì´ ë§¥ë½ì„ ì´í•´í•˜ê²Œ ë§Œë“¦
    - ìƒˆ ë‹µë³€ì€ historyì— ì €ì¥
    """

    rag_chain = initialize_rag_chain()

    # ìµœê·¼ ëŒ€í™” ê¸°ë¡ì„ promptì˜ 'question' ë¶€ë¶„ ì•ì— ë¶™ì„
    history_text = build_history_text(history)

    # ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  question í˜•ì‹
    full_question = f"""
(ì´ì „ ëŒ€í™” ë§¥ë½)
{history_text}

(í˜„ì¬ ì§ˆë¬¸)
{question}
"""

    # ë‹µë³€ ìƒì„±
    answer_text = rag_chain.invoke({
        "question": full_question,
        "grade": grade,
        "grade_rules": GRADE_RULES[grade]
    })

    # history ì €ì¥
    history.append({
        "question": question,
        "answer": answer_text
    })

    return answer_text


if __name__ == "__main__":
    history = []   # ë©€í‹°í„´ ëŒ€í™” ê¸°ë¡ ì €ì¥

    while True:
        q = input("\nì§ˆë¬¸ ì…ë ¥(exit ì¢…ë£Œ): ")
        if q.lower() == "exit":
            break

        grade = input("ë‚œì´ë„(ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ").strip()

        # ë©€í‹°í„´ ì ìš©ëœ ë‹µë³€ ì‹¤í–‰
        result = answer_with_history(q, grade, history)
        print("\nğŸ§  ë‹µë³€:\n", result)

        print("\nğŸ“œ í˜„ì¬ History í„´ ìˆ˜:", len(history))




# ==============================================================
# â˜…â˜…â˜… ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ â˜…â˜…â˜…
# ==============================================================

# if __name__ == "__main__":
#     print("\n=== ë¶€íŠ¸ìº í”„ RAG í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ ===")
#     print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥\n")

#     rag = initialize_rag_chain()

#     while True:
#         question = input("\nğŸ“Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
#         if question.lower() == "exit":
#             print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
#             break

#         grade = input("ğŸ’¡ ë‚œì´ë„ ì„ íƒ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ")
#         if grade.lower() == "exit":
#             print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
#             break

#         if grade not in GRADE_RULES:
#             print("âŒ ë‚œì´ë„ëŠ” 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#             continue

#         print("\nâ³ ë‹µë³€ ìƒì„± ì¤‘...\n")

#         result = rag.invoke({
#             "question": question,
#             "grade": grade,
#             "grade_rules": GRADE_RULES[grade]
#         })

#         print("ğŸ§  ì±—ë´‡ ë‹µë³€:\n")
#         print(result)
#         print("\n---------------------------------------")



# ==============================================================

# # CSV íŒŒì¼ ê²½ë¡œ
# CSV_PATH = r"C:\POTENUP\MumulMumul\notebooks\yojun\test_csv\rag_question_set.csv"

# if __name__ == "__main__":

#     # 1) CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
#     df = pd.read_csv(CSV_PATH, encoding="utf-8-sig")

#     # 2) answer ì»¬ëŸ¼ ì—†ìœ¼ë©´ ìƒì„±
#     if "answer" not in df.columns:
#         df["answer"] = ""

#     print("\nğŸ“Œ CSV ì˜ˆìƒ ì§ˆë¬¸ ìë™ í‰ê°€ ì‹œì‘\n")

#     save_interval = 5   # 5ê°œë§ˆë‹¤ ì €ì¥

#     # 3) ê° row ì²˜ë¦¬
#     for idx, row in df.iterrows():
#         question = str(row["question"]).strip()
#         grade = str(row["grade"]).strip()

#         # ë¹„ì–´ ìˆìœ¼ë©´ skip
#         if not question:
#             df.loc[idx, "answer"] = ""
#             continue

#         print(f"\n[{idx+1}] ì§ˆë¬¸: {question}")
#         print(f"ğŸ“˜ ë‚œì´ë„: {grade}")

#         try:
#             result = answer(question, grade)
#         except Exception as e:
#             result = f"ERROR: {e}"

#         df.loc[idx, "answer"] = result
#         print("â¡ ë‹µë³€ ì €ì¥ ì™„ë£Œ")

#         # ---- 5ê°œë§ˆë‹¤ ìë™ ì €ì¥ ì¶”ê°€ë¨ ----
#         if (idx + 1) % save_interval == 0:
#             df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
#             print(f"ğŸ’¾ {idx+1}ê°œ ì²˜ë¦¬ ì™„ë£Œ â†’ ì¤‘ê°„ ì €ì¥ë¨")

#     # 4) ì „ì²´ ì²˜ë¦¬ í›„ ìµœì¢… ì €ì¥
#     df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")

#     print("\nğŸ‰ ëª¨ë“  ì˜ˆìƒ ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì™„ë£Œ!")
#     print(f"ğŸ“„ ìµœì¢… íŒŒì¼ ì €ì¥ë¨ â†’ {CSV_PATH}")

# ==============================================================



# ==============================================================
# ì˜ˆì‹œ ì‹¤í–‰
# ==============================================================

# if __name__ == "__main__":
#     result = answer("ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜", grade="ì´ˆê¸‰")
#     print(result)

# # ì‚¬ìš© ì˜ˆì‹œ
# answer("ë¦¬ìŠ¤íŠ¸ ì•Œë ¤ì¤˜", grade="ì´ˆê¸‰")
from operator import itemgetter
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

DB_PATH = r"C:\POTENUP\MumulMumul\storage\vectorstore\curriculum_all_new"
COLLECTION = "curriculum_all_new"

LLM_MODEL = "gpt-4o-mini"
EMBEDDING_MODEL = "text-embedding-3-large"

SEARCH_K = 5
FETCH_K = 20

GRADE_RULES = {
    "ì´ˆê¸‰": """
- ì–´ë ¤ìš´ ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€
- ì „ë¬¸ ìš©ì–´ ë“±ì¥ ì‹œ ë°˜ë“œì‹œ ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ë¨¼ì € ì„¤ëª…
- ë¹„ìœ Â·ì˜ˆì‹œ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
- ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ê¸ˆì§€ (ì§§ê²Œ ëŠì–´ì„œ ì„¤ëª…)
""",
    "ì¤‘ê¸‰": """
- ê°œë…ì˜ í•µì‹¬ ì •ì˜ë¥¼ ì •í™•í•˜ê²Œ ì œê³µ
- í•„ìš” ì‹œ ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜ ë¶ˆí•„ìš”í•œ í™•ì¥ ê¸ˆì§€
- ì™œ ì´ëŸ° ê°œë…ì´ í•„ìš”í•œì§€ 1ë²ˆ ì„¤ëª…
- ì‹¤ë¬´ì—ì„œ í—·ê°ˆë¦¬ëŠ” í¬ì¸íŠ¸ë„ í•¨ê»˜ ì œê³µ
""",
    "ê³ ê¸‰": """
- ë‚´ë¶€ ë™ì‘ ì›ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
- êµ¬ì¡°, ë©”ì»¤ë‹ˆì¦˜, ë©”ëª¨ë¦¬Â·ì„±ëŠ¥ ë“± ì‹¬í™” ë‚´ìš© í¬í•¨ ê°€ëŠ¥
- í•„ìš”í•œ ê²½ìš° ìˆ˜ì‹Â·ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥
- ë‹¤ë¥¸ ê¸°ìˆ ê³¼ ë¹„êµ ì„¤ëª… ê°€ëŠ¥
"""
}

def initialize_rag_chain():
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)

    vectorstore = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings,
        collection_name=COLLECTION,
    )

    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": SEARCH_K, "fetch_k": FETCH_K}
    )

    template = """
    ë‹¹ì‹ ì€ ë¶€íŠ¸ìº í”„ í•™ìƒì„ ìœ„í•œ í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ì…ë‹ˆë‹¤.
    ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ [Context] ì•ˆì˜ ì •ë³´ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

    [í•™ìƒ ìˆ˜ì¤€]
    {grade}

    [ë‹µë³€ ê·œì¹™]
    {grade_rules}

    [ë‹µë³€ ì¡°ê±´]
    - ì„¤ëª…ì€ ë°˜ë“œì‹œ í•™ìƒ ìˆ˜ì¤€ì— ë§ì¶°ì„œ ì‘ì„±
    - ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±
    - ì¶œì²˜(íŒŒì¼ëª…, í˜ì´ì§€ ë“±) ë°˜ë“œì‹œ ëª…ì‹œ
    - Context ë°”ê¹¥ ì •ë³´ëŠ” ì‚¬ìš© ê¸ˆì§€

    -------------------------
    [Context]
    {context}

    [Question]
    {question}
    -------------------------
    """

    prompt = ChatPromptTemplate.from_template(template)
    model = ChatOpenAI(model=LLM_MODEL, temperature=0.2)

    rag_chain = (
        {
            # ì§ˆë¬¸ ë¬¸ìì—´ë§Œ êº¼ë‚´ì„œ retrieverì— ì „ë‹¬
            "context": itemgetter("question") | retriever,
            # ë‚˜ë¨¸ì§€ë„ ê°ê° í•„ìš”í•œ í‚¤ë§Œ ì „ë‹¬
            "question": itemgetter("question"),
            "grade": itemgetter("grade"),
            "grade_rules": itemgetter("grade_rules"),
        }
        | prompt
        | model
        | StrOutputParser()
    )

    return rag_chain


def answer(question, grade):
    if grade not in GRADE_RULES:
        raise ValueError("gradeëŠ” 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    rag = initialize_rag_chain()

    return rag.invoke({
        "question": question,
        "grade": grade,
        "grade_rules": GRADE_RULES[grade]
    })



if __name__ == "__main__":
    print("\n=== ë¶€íŠ¸ìº í”„ RAG í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥\n")

    rag = initialize_rag_chain()

    while True:
        question = input("\nğŸ“Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if question.lower() == "exit":
            print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        grade = input("ğŸ’¡ ë‚œì´ë„ ì„ íƒ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ")
        if grade.lower() == "exit":
            print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if grade not in GRADE_RULES:
            print("âŒ ë‚œì´ë„ëŠ” 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
            continue

        print("\nâ³ ë‹µë³€ ìƒì„± ì¤‘...\n")

        result = rag.invoke({
            "question": question,
            "grade": grade,
            "grade_rules": GRADE_RULES[grade]
        })

        print("ğŸ§  ì±—ë´‡ ë‹µë³€:\n")
        print(result)
        print("\n---------------------------------------")


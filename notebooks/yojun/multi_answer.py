from operator import itemgetter
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

DB_PATH = r"C:\POTENUP\MumulMumul\storage\vectorstore\curriculum_all_new"
COLLECTION = "curriculum_all_new"

LLM_MODEL = "gpt-4o-mini"
EMBEDDING_MODEL = "text-embedding-3-large"

SEARCH_K = 5
FETCH_K = 20


# -----------------------------------
#  í•™ìŠµ ìˆ˜ì¤€ë³„ í…œí”Œë¦¿
# -----------------------------------
GRADE_RULES = {
    "ì´ˆê¸‰": """
ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë°/ë°ì´í„°ë¥¼ ì²˜ìŒ ë°°ìš°ëŠ” ì´ˆê¸‰ìë¥¼ ë•ëŠ” í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ 6ë‹¨ê³„ í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

1) [ì§ˆë¬¸ ì´í•´]
- ì‚¬ìš©ìê°€ ì•Œê³  ì‹¶ì–´í•˜ëŠ” ë‚´ìš©ì„ í•œ ì¤„ë¡œ ë‹¤ì‹œ ì •ë¦¬í•©ë‹ˆë‹¤.

2) [í•µì‹¬ í•œ ì¤„ ìš”ì•½]
- ì´ˆë³´ìê°€ ë‹¨ë²ˆì— ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê²°ë¡ ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.

3) [ì‰¬ìš´ ì„¤ëª…]
- ì–´ë ¤ìš´ ìš©ì–´, ì˜ì–´, ì¶•ì•½ì–´ëŠ” ê°€ëŠ¥í•œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ê¼­ ì‚¬ìš©í•´ì•¼ í•œë‹¤ë©´ ê´„í˜¸ë¡œ ì‰¬ìš´ ëœ»ì„ ì ìŠµë‹ˆë‹¤.

4) [ë¹„ìœ  / ì˜ˆì‹œ]
- í˜„ì‹¤ ë¹„ìœ  1ê°œ ì´ìƒ
- ê°„ë‹¨í•œ ì˜ˆì‹œ ì½”ë“œ 1ê°œ

5) [ì¶”ê°€ë¡œ ì•Œë©´ ì¢‹ì€ ê²ƒ]
- 1~2ì¤„ë§Œ í™•ì¥ ì„¤ëª… (ë„ˆë¬´ ê¹Šì€ ë‚´ìš© ê¸ˆì§€)

6) [ì¶œì²˜]
- íŒŒì¼ëª….pdf / p.ìˆ«ì í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ëª…ì‹œ

ì£¼ì˜:
- ë¬¸ì¥ì€ ì§§ê²Œ, ì‰½ê²Œ.
- contextì— ì—†ëŠ” ë‚´ìš©ì€ ìƒì„±í•˜ì§€ ì•Šê¸°.
""",

    "ì¤‘ê¸‰": """
- ê°œë…ì˜ í•µì‹¬ ì •ì˜ ì œê³µ
- í•„ìš” ì‹œ ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥
- ì™œ í•„ìš”í•œ ê°œë…ì¸ì§€ ì„¤ëª…
- ì‹¤ë¬´ì—ì„œ ìì£¼ í—·ê°ˆë¦¬ëŠ” ê°œë… í¬í•¨
- ì˜ˆì‹œ ì½”ë“œ í¬í•¨ ê°€ëŠ¥
- ì¶œì²˜ í¬í•¨
""",

    "ê³ ê¸‰": """
- ë‚´ë¶€ ë™ì‘ ì›ë¦¬ ì¤‘ì‹¬ ì„¤ëª…
- êµ¬ì¡°, ë©”ì»¤ë‹ˆì¦˜, ì„±ëŠ¥ ë“± ì‹¬í™” ê°œë… í¬í•¨
- ìˆ˜ì‹Â·ì „ë¬¸ìš©ì–´ ì‚¬ìš© ê°€ëŠ¥
- ë‹¤ë¥¸ ê¸°ìˆ  ë¹„êµ ê°€ëŠ¥
- ì¶œì²˜ í¬í•¨
"""
}


# -----------------------------------
#  RAG ì´ˆê¸°í™”
# -----------------------------------
def initialize_rag_chain():
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)

    vectorstore = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings,
        collection_name=COLLECTION,
    )

    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": SEARCH_K, "fetch_k": FETCH_K}
    )

    template = """
ë‹¹ì‹ ì€ ë¶€íŠ¸ìº í”„ í•™ìŠµ ìë£Œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

[ì¤‘ìš” ì§€ì¹¨]
- ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ Contextì—ì„œë§Œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
- Contextì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
- í•™ìƒ ìˆ˜ì¤€(ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)ì— ë§ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- ì¶œì²˜(íŒŒì¼ëª… + í˜ì´ì§€)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.

[í•™ìƒ ìˆ˜ì¤€]
{grade}

[ë‹µë³€ ê·œì¹™]
{grade_rules}

-------------------------------------
[Context]
{context}

[Question]
{question}
-------------------------------------
ìœ„ í˜•ì‹ì„ ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.
"""

    prompt = ChatPromptTemplate.from_template(template)
    model = ChatOpenAI(model=LLM_MODEL, temperature=0.2)

    rag_chain = (
        {
            "context": itemgetter("question") | retriever,
            "question": itemgetter("question"),
            "grade": itemgetter("grade"),
            "grade_rules": itemgetter("grade_rules"),
        }
        | prompt
        | model
        | StrOutputParser()
    )

    return rag_chain


# -----------------------------------
#  ë‹¨ì¼ ì§ˆë¬¸ ë‹µë³€
# -----------------------------------
def answer(question, grade, rag_chain=None):
    if grade not in GRADE_RULES:
        raise ValueError("gradeëŠ” 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    if rag_chain is None:
        rag_chain = initialize_rag_chain()

    return rag_chain.invoke({
        "question": question,
        "grade": grade,
        "grade_rules": GRADE_RULES[grade]
    })


# -----------------------------------
#  ì—¬ëŸ¬ ì§ˆë¬¸ ìë™ ë¶„ë¦¬
# -----------------------------------
def split_questions(user_message: str) -> list[str]:
    splitter = ChatOpenAI(model=LLM_MODEL, temperature=0)

    split_prompt = ChatPromptTemplate.from_template(
        """
ì‚¬ìš©ìì˜ ì…ë ¥ì—ì„œ 'ì„œë¡œ ë‹¤ë¥¸ ì§ˆë¬¸'ì„ ì˜ë¯¸ ë‹¨ìœ„ë³„ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
1. ì§ˆë¬¸1
2. ì§ˆë¬¸2
3. ì§ˆë¬¸3

ì‚¬ìš©ì ì…ë ¥:
{message}
"""
    )

    chain = split_prompt | splitter | StrOutputParser()
    raw = chain.invoke({"message": user_message})

    questions = []
    for line in raw.splitlines():
        line = line.strip()
        if line and line[0].isdigit() and "." in line:
            _, q = line.split(".", 1)
            if q.strip():
                questions.append(q.strip())

    if not questions:
        return [user_message.strip()]

    return questions


# -----------------------------------
#  ì—¬ëŸ¬ ì§ˆë¬¸ â†’ ì§ˆë¬¸ë³„ RAG í˜¸ì¶œ â†’ í†µí•© ì¶œë ¥
# -----------------------------------
def multi_answer(user_message: str, grade: str):
    questions = split_questions(user_message)

    rag_chain = initialize_rag_chain()

    results = []

    for idx, q in enumerate(questions, start=1):
        try:
            ans = answer(q, grade, rag_chain=rag_chain)
        except Exception as e:
            ans = f"ERROR: {e}"

        block = f"""
### ì§ˆë¬¸ {idx}
> {q}

{ans}

-------------------------------------
"""
        results.append(block)

    return "\n".join(results)


# -----------------------------------
#  MAIN ë£¨í”„ (ë‹¨ì¼ vs ë³µìˆ˜ ìë™ ê°ì§€)
# -----------------------------------
if __name__ == "__main__":
    print("\n=== ë¶€íŠ¸ìº í”„ RAG í•™ìŠµ ë„ìš°ë¯¸ (ë©€í‹° ì§ˆë¬¸ ì™„ì „ ì§€ì›) ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥\n")

    while True:
        user_msg = input("\nğŸ“Œ ì§ˆë¬¸ ì…ë ¥: ")
        if user_msg.lower().strip() == "exit":
            break

        grade = input("ğŸ’¡ ë‚œì´ë„ ì„ íƒ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ").strip()
        if grade.lower().strip() == "exit":
            break

        print("\nâ³ ë‹µë³€ ìƒì„± ì¤‘...\n")

        # ì§ˆë¬¸ ìë™ ë¶„ë¦¬
        qs = split_questions(user_msg)

        # 1ê°œë©´ â†’ ë‹¨ì¼ answer()
        if len(qs) <= 1:
            result = answer(user_msg, grade)
        else:
            # ì—¬ëŸ¬ ê°œë©´ â†’ multi_answer()
            result = multi_answer(user_msg, grade)

        print("ğŸ§  í•™ìŠµ ë„ìš°ë¯¸ ë‹µë³€:\n")
        print(result)
        print("\n============================================")
